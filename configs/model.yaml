seq2seq:
    input_dim: 6000
    output_dim: 6000
    emb_dim: 256
    hidden_dim: 512
    n_layers: 2
    dropout_ratio: 0.5
    pad_idx: 1
    max_len: 100


seq2seq_attn:
    input_dim: 6000
    output_dim: 6000
    emb_dim: 256
    hidden_dim: 512
    dropout_ratio: 0.5
    pad_idx: 1
    max_len: 100


transformer:
    input_dim: 6000
    output_dim: 6000
    emb_dim: 256
    hidden_dim: 256
    pff_dim: 512
    n_layers: 3
    n_heads: 8
    dropout_ratio: 0.1
    pad_idx: 1
    max_len: 100